{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection on a time serie \n",
    "We will use three unsupervised machine learning algorithms to detect anomaly on a time series: \n",
    "\n",
    "\n",
    "KNN (source: Rajeev Rastogi Sridhar Ramaswamy and Kyuseok Shim. Efficient algorithms for mining outliers from large data sets. in proceedings of the international conference on management of data (sigmod). page 427â€“438,\n",
    "2000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pyod.models.knn import KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some helps function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the contamination percentage time serie if it is labeled\n",
    "def computeContamination(filepath) :\n",
    "    df = pd.read_csv(filepath)\n",
    "    #print('new')\n",
    "    labels = []\n",
    "    if 'anomaly' in df.columns:\n",
    "        labels= df['anomaly'].to_numpy()\n",
    "    else:\n",
    "        labels = df['is_anomaly'].to_numpy()\n",
    "    contamination = labels.sum() / len(labels)\n",
    "    # Use smallest positive float as contamination if there are no anomalies in dataset\n",
    "    contamination = np.nextafter(0, 1) if contamination <= 0. else contamination\n",
    "    return contamination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ROC-AUC\n",
    "#return the auc or np.nan if Auc can not be computed\n",
    "def compute_auc(tm_dataframe):\n",
    "    #compute AUC\n",
    "    y = []\n",
    "    if 'anomaly' in tm_dataframe.columns:\n",
    "        y= tm_dataframe['anomaly'].to_numpy()\n",
    "    else:\n",
    "        y = tm_dataframe['is_anomaly'].to_numpy()\n",
    "    #print(y)\n",
    "    #y = df['is_anomaly'].to_numpy()\n",
    "    y_score = tm_dataframe['scores'].to_numpy()\n",
    "    #auc =  roc_auc_score(y, y_score)\n",
    "    if len(set(y)) > 1:\n",
    "        auc =  roc_auc_score(y, y_score)\n",
    "        return auc\n",
    "    else:\n",
    "        #print('found')\n",
    "        #print(filepath)\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Knn(knn_params, filepath ): \n",
    "    #get the time serie\n",
    "    df_timeserie = pd.read_csv(filepath)\n",
    "    contamination = computeContamination(filepath)\n",
    "    if contamination > 0.5 :\n",
    "        print('contamination is more than')\n",
    "        contamination = 0.5\n",
    "    \n",
    "    #prepare values of the dataframe to fit the model\n",
    "    X = []\n",
    "    if  df_timeserie.iloc[:, 0].dtypes == object :\n",
    "        myindex = df_timeserie.index.to_numpy()\n",
    "        x_value = df_timeserie.iloc[:, 1].to_numpy()\n",
    "        X = np.concatenate((myindex.reshape(-1,1), x_value.reshape(-1,1)), axis=1)\n",
    "    else:   \n",
    "            \n",
    "        X = df_timeserie.iloc[:, 0:1].to_numpy()\n",
    "    #fit the model\n",
    "    knn = KNN(contamination= contamination, n_neighbors= knn_params['n_neighbors'], \n",
    "    leaf_size=20, p= 2 ,\n",
    "    n_jobs=  1)\n",
    "    knn.fit(X)\n",
    "\n",
    "    #save score\n",
    "    y_scores = knn.decision_function(X)\n",
    "    df_timeserie['scores'] = y_scores\n",
    "    return df_timeserie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"1.test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general parameter:\n",
    "# parameters are not optimized. It is just to illustrate how we can KNN to detect or score points in a time serie\n",
    "knnParam = {    \n",
    "    'n_neighbors': 150,\n",
    "    'leaf_size':20,\n",
    "    'distance_metric_order' :2,\n",
    "    'n_jobs' : 1,\n",
    "    'random_state' :42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = Knn(knnParam, filename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5351980460921844\n"
     ]
    }
   ],
   "source": [
    "auc = compute_auc(df_knn)\n",
    "print(auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
